id: 03_getting_started_data_pipeline
namespace: zoomcamp

# 1. INPUTS (Dynamic Configuration)
# Instead of hardcoding "brand" and "price" inside the Python script,
# we ask for them here. This makes the pipeline reusable.
# If marketing wants "category" next week, they just change the input, not the code.
inputs:
  - id: columns_to_keep
    type: ARRAY
    itemType: STRING
    defaults:
      - brand
      - price

tasks:
  # ---------------------------------------------------------
  # STEP 1: EXTRACT (Get the raw data)
  # ---------------------------------------------------------
  - id: extract
    type: io.kestra.plugin.core.http.Download
    uri: https://dummyjson.com/products
    # OUTPUT: This task saves the downloaded file to Kestra's internal storage.
    # We can reference it later using {{ outputs.extract.uri }}

  # ---------------------------------------------------------
  # STEP 2: TRANSFORM (Clean with Python)
  # ---------------------------------------------------------
  - id: transform
    type: io.kestra.plugin.scripts.python.Script
    # Using 'alpine' makes this container tiny and fast to start.
    containerImage: python:3.11-alpine
    
    # THE BRIDGE (Crucial Concept):
    # This maps the file from Kestra's storage into the Docker container.
    # "Take the file from Task 1, and save it inside the container as 'data.json'"
    inputFiles:
      data.json: "{{outputs.extract.